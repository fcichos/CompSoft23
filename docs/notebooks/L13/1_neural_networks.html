

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Neural Networks &mdash; Introduction to Computer-based Physical Modeling 1 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"TeX": {"equationNumbers": {"autoNumber": "AMS", "useLabelIds": true}}, "tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
        <script src="https://unpkg.com/@jupyter-widgets/html-manager@^0.18.0/dist/embed-amd.js"></script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/theme_overrides.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Introduction to Computer-based Physical Modeling
          

          
            
            <img src="../../_static/mona_logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Course Information:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/website.html">This Website</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/schedule.html">Course Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/assignments.html">Assignments</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/exam.html">Exams</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/resources.html">Resources</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../course-info/resources.html#molecular-nanophotonics-group">Molecular Nanophotonics Group</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-info/resources.html#python-documentation">Python Documentation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../course-info/resources.html#python-tutorials">Python Tutorials</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../course-info/instructor.html">Instructor</a></li>
</ul>
<p class="caption"><span class="caption-text">Jupyter Notebooks:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/Intro/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/Introduction2Jupyter.html">Introduction to Jupyter</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#What-is-Jupyter-Notebook?">What is Jupyter Notebook?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#Notebook-editor">Notebook editor</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#Kernels">Kernels</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/Introduction2Jupyter.html#Notebook-documents">Notebook documents</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/NotebookEditor.html">Notebook editor</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Edit-mode">Edit mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Command-mode">Command mode</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Keyboard-navigation">Keyboard navigation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Running-code">Running code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/NotebookEditor.html#Managing-the-kernel">Managing the kernel</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/EditCells.html">Entering code</a></li>
<li class="toctree-l1"><a class="reference internal" href="../Intro/EditCells.html#Entering-Markdown">Entering Markdown</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Markdown-basics">Markdown basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Headings">Headings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Embedded-code">Embedded code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#LaTeX-equations">LaTeX equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Images">Images</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Intro/EditCells.html#Videos">Videos</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 1:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L1/overview_1.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L1/1_variables.html">Variables and types</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L1/1_variables.html#Symbol-names">Symbol names</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/1_variables.html#Variable-Assignment">Variable Assignment</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/1_variables.html#Number-types">Number types</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Integers">Integers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Floating-Point">Floating Point</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Complex-Numbers">Complex Numbers</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L1/1_variables.html#Type-casting">Type casting</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L1/2_operators.html">Operators and comparisons</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L1/3_datatypes.html">Data Types in Python</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Strings">Strings</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Lists">Lists</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Tuples">Tuples</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/3_datatypes.html#Dictionaries">Dictionaries</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L1/4_modules.html">Modules and namespaces</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L1/4_modules.html#Modules">Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/4_modules.html#Namespaces">Namespaces</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L1/4_modules.html#Contents-of-a-module">Contents of a module</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L1/assignment_1.html">Exercise 1</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 2:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L2/overview_2.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L2/1_numpy.html">NumPy arrays</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L2/1_numpy.html#Creating-Numpy-Arrays">Creating Numpy Arrays</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#From-lists">From lists</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Using-array-generating-functions">Using array-generating functions</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#linspace-and-logspace">linspace and logspace</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#mgrid">mgrid</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#diag">diag</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#zeros-and-ones">zeros and ones</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/1_numpy.html#Manipulating-NumPy-arrays">Manipulating NumPy arrays</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Slicing">Slicing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Reshaping">Reshaping</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Adding-a-new-dimension:-newaxis">Adding a new dimension: newaxis</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Stacking-and-repeating-arrays">Stacking and repeating arrays</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#Tile-and-repeat">Tile and repeat</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#Concatenate">Concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L2/1_numpy.html#Hstack-and-vstack">Hstack and vstack</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L2/1_numpy.html#Applying-mathematical-functions">Applying mathematical functions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Operation-involving-one-array">Operation involving one array</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L2/1_numpy.html#Operations-involving-multiple-arrays">Operations involving multiple arrays</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L2/3_randomnumbers.html">Random numbers</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Uniformly-distributed-random-numbers">Uniformly distributed random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Normally-distributed-random-numbers">Normally distributed random numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Exponentially-distributed-numbers">Exponentially distributed numbers</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L2/3_randomnumbers.html#Random-distribution-of-integers">Random distribution of integers</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L2/assignment_2.html">Exercise 2</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 3:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L3/overview_3.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L3/1_input_output.html">Input and output</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L3/1_input_output.html#Keyboard-input">Keyboard input</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/1_input_output.html#Screen-output">Screen output</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/1_input_output.html#File-input/output">File input/output</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/1_input_output.html#File-I/O-with-NumPy">File I/O with NumPy</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Reading-data-from-a-text-file">Reading data from a text file</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Writing-data-to-a-text-file">Writing data to a text file</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../L3/1_input_output.html#File-I/O-with-Pandas">File I/O with Pandas</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Short-intro-to-Pandas">Short intro to Pandas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L3/1_input_output.html#Reading-CSV-data-with-Pandas">Reading CSV data with Pandas</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L3/2_flowcontrol.html">Flow Control</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L3/2_flowcontrol.html#Conditionals:-if,-elif,-and-else-statements">Conditionals: if, elif, and else statements</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#If-example">If example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#If-else-example">If else example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#If,-elif,-else-example">If, elif, else example</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#Combining-conditions">Combining conditions</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L3/2_flowcontrol.html#Loops">Loops</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#For-loops">For loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#While-loops">While loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#Loops-and-array-operations">Loops and array operations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/2_flowcontrol.html#List-comprehensions">List comprehensions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L3/3_functions.html">Functions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Function-definition">Function definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Variables-in-functions">Variables in functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Functions-with-more-than-one-input-or-output">Functions with more than one input or output</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L3/3_functions.html#Positional-and-keyword-arguments">Positional and keyword arguments</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L3/3_functions.html#Functions-with-variable-number-of-arguments">Functions with variable number of arguments</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Unnamed-functions-(lambda-function)">Unnamed functions (lambda function)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L3/3_functions.html#Functions-as-arguments-of-functions">Functions as arguments of functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L3/4_exceptions.html">Exceptions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L3/assignment_3.html">Exercise 3</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 4:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L4/overview_4.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L4/1_classes.html">Classes and Objects</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L4/1_classes.html#Definition-of-Classes">Definition of Classes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/1_classes.html#Class-Methods">Class Methods</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L4/1_classes.html#The-__init__-method">The <code class="docutils literal notranslate"><span class="pre">__init__</span></code> method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L4/1_classes.html#The-__str__-method">The <code class="docutils literal notranslate"><span class="pre">__str__</span></code> method</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L4/1_classes.html#Class-and-object-variables">Class and object variables</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L4/2_brownian_motion.html">Brownian Motion</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Physics">Physics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Class-Planning">Class Planning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Simulating">Simulating</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Plotting-the-trajectories">Plotting the trajectories</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/2_brownian_motion.html#Characterizing-the-Brownian-motion">Characterizing the Brownian motion</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L4/2_brownian_motion.html#Calculate-the-particle-velocity">Calculate the particle velocity</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L4/2_brownian_motion.html#Calculate-the-particle-mean-squared-displacement">Calculate the particle mean squared displacement</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L4/3_animations.html">Animations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Import-Modules">Import Modules</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Particle-class">Particle class</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Create-a-set-of-particles">Create a set of particles</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Canvas-and-drawing-function">Canvas and drawing function</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L4/3_animations.html#Threading-for-animation">Threading for animation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L4/assignment_4.html">Exercise 4</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 5:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L5/overview_5.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L5/1_differentiation.html">Numerical Differentiation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L5/1_differentiation.html#First-order-derivative">First order derivative</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/1_differentiation.html#Matrix-version-of-the-first-derivative">Matrix version of the first derivative</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/1_differentiation.html#Second-order-derivative">Second order derivative</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/1_differentiation.html#SciPy-Module">SciPy Module</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/1_differentiation.html#Matrix-version">Matrix version</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L5/2_integration.html">Numerical Integration</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L5/2_integration.html#Box-method">Box method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/2_integration.html#Trapezoid-method">Trapezoid method</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/2_integration.html#Simpson-method">Simpson method</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L5/3_solving_ODEs.html">Solving ODEs</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Harmonic-Oscillator">Harmonic Oscillator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Implicit-Solution---Crank-Nicholson">Implicit Solution - Crank Nicholson</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Define-Matrices">Define Matrices</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Use-Initial-Conditions">Use Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Solution">Solution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Explicit-Solution---Numerical-Integration">Explicit Solution - Numerical Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Euler-Method">Euler Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Euler-Cromer-Method">Euler Cromer Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Midpoint-Method">Midpoint Method</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Putting-it-all-together">Putting it all together</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L5/3_solving_ODEs.html#The-definition-of-the-problem">The definition of the problem</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L5/3_solving_ODEs.html#Solving-the-problem">Solving the problem</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Solving-the-Harmonic-Oscillator-in-SciPy">Solving the Harmonic Oscillator in SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Definition">Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id1">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#Plotting">Plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L5/3_solving_ODEs.html#Damped-Driven-Pendulum-in-SciPy">Damped Driven Pendulum in SciPy</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id2">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id3">Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id4">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L5/3_solving_ODEs.html#id5">Plotting</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 6:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L6/overview_6.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L6/1_covid19.html">COVID19</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#The-Kermack-McKendrick-Model">The Kermack-McKendrick Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Model-Equation">Model Equation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Setup">Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Definition">Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Solution">Solution</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Plotting">Plotting</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/1_covid19.html#Real-COVID19-numbers">Real COVID19 numbers</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Total-number-of-cases">Total number of cases</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Number-of-Deaths">Number of Deaths</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#New-cases-per-day">New cases per day</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/1_covid19.html#Current-cases">Current cases</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L6/2_coupled_pendula.html">Coupled Pendula</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L6/2_coupled_pendula.html#Description-of-the-problem">Description of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Sketch">Sketch</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Equations-of-motion">Equations of motion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L6/2_coupled_pendula.html#Solving-the-problem">Solving the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Setting-up-the-function">Setting up the function</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Define-initial-parameters">Define initial parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Solve-the-equation-of-motion">Solve the equation of motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Animation">Animation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L6/2_coupled_pendula.html#Normal-Modes">Normal Modes</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#In-phase-motion">In-phase motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Out-of-phase-motion">Out-of-phase motion</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Beat-case">Beat case</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L6/2_coupled_pendula.html#Computation-of-energy-(here-for-the-beat-case)">Computation of energy (here for the beat case)</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Potential-energy-of-the-pendula">Potential energy of the pendula</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Potential-energy-of-the-spring">Potential energy of the spring</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Kinetic-energies">Kinetic energies</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Total-energy">Total energy</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L6/2_coupled_pendula.html#Total-energy-exchange-of-the-pendula">Total energy exchange of the pendula</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L6/3_fourier_analysis.html">Fourier Analysis</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L6/3_fourier_analysis.html#Fourier-series">Fourier series</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/3_fourier_analysis.html#Fourier-transform">Fourier transform</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L6/3_fourier_analysis.html#Frequency-analysis-of-our-coupled-pendula">Frequency analysis of our coupled pendula</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 7:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L7/overview_7.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L7/1_spring_pendulum.html">Spring Pendulum</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L7/1_spring_pendulum.html#Physical-Model">Physical Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Equations-of-motion">Equations of motion</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L7/1_spring_pendulum.html#Numerical-Solution">Numerical Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Initial-parameters">Initial parameters</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/1_spring_pendulum.html#Plotting">Plotting</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L7/1_spring_pendulum.html#Angle-and-Length-over-Time">Angle and Length over Time</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L7/2_planetary_motion.html">Planetary Motion</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L7/2_planetary_motion.html#Physical-Model">Physical Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L7/2_planetary_motion.html#Numerical-Solution">Numerical Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/2_planetary_motion.html#Initial-Parameters:-Planets">Initial Parameters: Planets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/2_planetary_motion.html#Solution:-Planets">Solution: Planets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/2_planetary_motion.html#Plotting:-Planets">Plotting: Planets</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L7/2_planetary_motion.html#Trajectory">Trajectory</a></li>
<li class="toctree-l4"><a class="reference internal" href="../L7/2_planetary_motion.html#Energy">Energy</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L7/3_diffusion_equation.html">Diffusion equation</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L7/3_diffusion_equation.html#Physical-Model">Physical Model</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Spatial-derivative">Spatial derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Temporal-derivative">Temporal derivative</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Bringing-all-together">Bringing all together</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L7/3_diffusion_equation.html#Numerical-Solution">Numerical Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Setup-Domain">Setup Domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Initial-Conditions">Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Matrix-Setup">Matrix Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L7/3_diffusion_equation.html#Solution">Solution</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L7/assignment_7.html">Exercise 7</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 8:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L8/overview_8.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L8/1_curve_fitting.html">Curve fitting</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Idea">Idea</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Least-squares">Least squares</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Data">Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Least-square-fitting">Least square fitting</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L8/1_curve_fitting.html#\chi-squared-value"><span class="math notranslate nohighlight">\(\chi\)</span>-squared value</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L8/1_curve_fitting.html#Residuals">Residuals</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L8/1_curve_fitting.html#Covariance-matrix">Covariance matrix</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 9:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L9/overview_9.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L9/2_spherical_waves.html">Spherical waves</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Equations">Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Electric-field">Electric field</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Plot-the-intensity-in-an-image-plane">Plot the intensity in an image plane</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/2_spherical_waves.html#Interference-between-a-spherical-and-a-plane-wave">Interference between a spherical and a plane wave</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L9/3_huygens_principle.html">Huygens principle</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/3_huygens_principle.html#Diffraction-pattern-of-a-single-slit">Diffraction pattern of a single slit</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/3_huygens_principle.html#Farfield-vs. nearfield">Farfield vs. nearfield</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/3_huygens_principle.html#Comparison-to-the-analytical-solution">Comparison to the analytical solution</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L9/4_gaussian_beams.html">Gaussian Beam</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Equations">Equations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Intensity-plot">Intensity plot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L9/4_gaussian_beams.html#Intensity-profiles">Intensity profiles</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L9/assignment_9.html">Exercise 9</a></li>
</ul>
<p class="caption"><span class="caption-text">Lecture 10:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L10/overview_10.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L10/1_quantum_mechanics.html">Quantum Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Quantum-Mechanics-in-a-Nutshell">Quantum Mechanics in a Nutshell</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Time-dependent-Schrödinger-equation">Time dependent Schrödinger equation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Stationary-Schrödinger-equation">Stationary Schrödinger equation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Recap:-Implicit-Solution">Recap: Implicit Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/1_quantum_mechanics.html#Potential-energy">Potential energy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L10/2_particle_in_a_box.html">Particle in a box</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Definition-of-the-problem">Definition of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Potential-energy">Potential energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Energies-of-bound-states">Energies of bound states</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/2_particle_in_a_box.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L10/3_harmonic_oscillator.html">Harmonic Oscillator</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Definition-of-the-problem">Definition of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Potential-energy">Potential energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Plotting">Plotting</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Energies-of-the-states">Energies of the states</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/3_harmonic_oscillator.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L10/4_periodic_potential.html">Periodic Potential</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L10/4_periodic_potential.html#Definition-of-the-problem">Definition of the problem</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Potential-energy">Potential energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Kinetic-energy">Kinetic energy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Solution">Solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L10/4_periodic_potential.html#Plotting">Plotting</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L10/4_periodic_potential.html#Energy-states">Energy states</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L10/4_periodic_potential.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 11:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L11/overview_11.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L11/1_quantum_dynamics.html">Time Dependent Quantum Mechanics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Time-dependent-Schrödinger-equation">Time dependent Schrödinger equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Wavepackets">Wavepackets</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Demonstration-of-superposition-of-plane-waves">Demonstration of superposition of plane waves</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Wavepacket">Wavepacket</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Wavepacket-with-rectangular-amplitude">Wavepacket with rectangular amplitude</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Gaussian-Wave-Packet">Gaussian Wave Packet</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/1_quantum_dynamics.html#Time-evolution-of-a-Gaussian-Wavepacket">Time evolution of a Gaussian Wavepacket</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L11/2_particle_in_a_box.html">Wavepacket in a Potential Box</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Problem-Setup">Problem Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Initial-conditions">Initial conditions</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Eigenfunctions">Eigenfunctions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Quality-of-the-coefficients">Quality of the coefficients</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Animation">Animation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/2_particle_in_a_box.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L11/3_tunneling.html">Tunneling through a barrier</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Schrödinger-equation-for-the-momentum">Schrödinger equation for the momentum</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Crank-Nicolson-Solution">Crank Nicolson Solution</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Setup-Domain">Setup Domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Initial-Conditions">Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Matrix-Setup">Matrix Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Propagation-Matrix">Propagation Matrix</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Animation-setup">Animation setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Animation">Animation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Split-Step-Method">Split Step Method</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#id1">Setup Domain</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Potential-energy-landscape">Potential energy landscape</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Initial-wavepacket">Initial wavepacket</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Fourier-Transform-Setup">Fourier Transform Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#Phase-Factor-per-Timestep">Phase Factor per Timestep</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#id2">Animation setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L11/3_tunneling.html#id3">Animation</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L11/3_tunneling.html#Where-to-go-from-here?">Where to go from here?</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 12:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../lectures/L12/overview_12.html">Lecture Contents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../L12/1_hydrodynamics.html">Hydrodynamics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L12/1_hydrodynamics.html#Falling-sphere">Falling sphere</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Setup">Setup</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Function-definition">Function definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Initial-Conditions">Initial Conditions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Numerical-solution">Numerical solution</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Analytical-solution">Analytical solution</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L12/1_hydrodynamics.html#Stokes-equation">Stokes equation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L12/1_hydrodynamics.html#Fundamental-Solutions-of-the-Stokes-Equation">Fundamental Solutions of the Stokes Equation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Stokeslet">Stokeslet</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Source-dipole">Source dipole</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/1_hydrodynamics.html#Sum-of-both-solutions">Sum of both solutions</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../L12/2_reinforcement_learning.html">Machine Learning and Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Overview">Overview</a></li>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Reinforcement-Learning">Reinforcement Learning</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Markov-Decision-Process">Markov Decision Process</a><ul>
<li class="toctree-l4"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Methods-or-RL">Methods or RL</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Navigating-a-Grid-World">Navigating a Grid World</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Initialize-Reinforcement-Learning">Initialize Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#List-of-actions">List of actions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Initial-state">Initial state</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Reinforcement-Learning-Loop">Reinforcement Learning Loop</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Convergence-of-the-Q-learning">Convergence of the Q-learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Policy">Policy</a></li>
<li class="toctree-l3"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Plot-the-policy">Plot the policy</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../L12/2_reinforcement_learning.html#Where-to-go-from-here">Where to go from here</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Lecture 13:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="1_deep_learning.html">Neural Networks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="1_deep_learning.html#The-MNIST-Data-Set">The MNIST Data Set</a><ul>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Load-the-data">Load the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Normalize-the-data">Normalize the data</a></li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Preparing-training-and-testing-data">Preparing training and testing data</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="1_deep_learning.html#A-Single-Neuron">A Single Neuron</a><ul>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Forward-Propogation">Forward Propogation</a></li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Loss-Function">Loss Function</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="1_deep_learning.html#Trainging-the-Network">Trainging the Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Backward-Propagation">Backward Propagation</a></li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Stochastic-Gradient-Descent">Stochastic Gradient Descent</a></li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Build-an-Train">Build an Train</a></li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Testing-our-model">Testing our model</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="1_deep_learning.html#Network-with-Hidden-Layers">Network with Hidden Layers</a></li>
<li class="toctree-l2"><a class="reference internal" href="1_deep_learning.html#Multiclass-Network">Multiclass Network</a><ul>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Changes-to-the-model">Changes to the model</a><ul>
<li class="toctree-l4"><a class="reference internal" href="1_deep_learning.html#Forward-Pass">Forward Pass</a></li>
<li class="toctree-l4"><a class="reference internal" href="1_deep_learning.html#id3">Loss Function</a></li>
<li class="toctree-l4"><a class="reference internal" href="1_deep_learning.html#Back-Propagation">Back Propagation</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="1_deep_learning.html#Build-and-Train">Build and Train</a><ul>
<li class="toctree-l4"><a class="reference internal" href="1_deep_learning.html#Model-performance">Model performance</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="1_deep_learning.html#Test-the-model">Test the model</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="2_deep_learning_keras.html">Neural Network with Keras</a><ul>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#MNIST-Data-Set-(Keras)">MNIST Data Set (Keras)</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Build-the-model">Build the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Compile-the-model">Compile the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Train-the-model">Train the model</a></li>
<li class="toctree-l2"><a class="reference internal" href="2_deep_learning_keras.html#Testing-the-model">Testing the model</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Introduction to Computer-based Physical Modeling</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Neural Networks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            
              <a href="https://github.com/fcichos/website/blob/master//source/notebooks/L13/1_neural_networks.ipynb" class="fa fa-github"> Edit on GitHub</a>
            
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container,
div.nbinput.container div.prompt,
div.nbinput.container div.input_area,
div.nbinput.container div[class*=highlight],
div.nbinput.container div[class*=highlight] pre,
div.nboutput.container,
div.nboutput.container div.prompt,
div.nboutput.container div.output_area,
div.nboutput.container div[class*=highlight],
div.nboutput.container div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt a.copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="admonition note">
<p>This page was generated from <a href="#id3"><span class="problematic" id="id4">`source/notebooks/L13/1_neural_networks.ipynb`_</span></a>.
<span class="raw-html"><br/><a href="https://mybinder.org/v2/gh/fcichos/website/master?urlpath=tree/source/notebooks/L13/1_neural_networks.ipynb"><img alt="Binder badge" src="https://img.shields.io/badge/launch-full%20binder-red.svg" style="vertical-align:text-bottom"></a></span></p>
</div>
<div class="section" id="Neural-Networks">
<h1>Neural Networks<a class="headerlink" href="#Neural-Networks" title="Permalink to this headline">¶</a></h1>
<p>Neural networks are one of the most commonly used machine learning objects nowadays. Mostly these systems are known as <strong>deep neural networks</strong>, which just says something about how many layers in which neurons are arranged exist. We will in this lecture have a look at the basic unit, the neuron, and how to connect and train a network. We will do all ourselves, that means, we will not use one of the many existing python modules, that simplifies the task.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="o">%</span><span class="k">config</span> InlineBackend.figure_format = &#39;retina&#39;


<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="o">.</span><span class="n">update</span><span class="p">({</span><span class="s1">&#39;font.size&#39;</span><span class="p">:</span> <span class="mi">18</span><span class="p">,</span>
                     <span class="s1">&#39;axes.titlesize&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                     <span class="s1">&#39;axes.labelsize&#39;</span><span class="p">:</span> <span class="mi">20</span><span class="p">,</span>
                     <span class="s1">&#39;axes.labelpad&#39;</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
                     <span class="s1">&#39;lines.linewidth&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
                     <span class="s1">&#39;lines.markersize&#39;</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
                     <span class="s1">&#39;xtick.labelsize&#39;</span> <span class="p">:</span> <span class="mi">18</span><span class="p">,</span>
                     <span class="s1">&#39;ytick.labelsize&#39;</span> <span class="p">:</span> <span class="mi">18</span><span class="p">,</span>
                     <span class="s1">&#39;xtick.top&#39;</span> <span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="s1">&#39;xtick.direction&#39;</span> <span class="p">:</span> <span class="s1">&#39;in&#39;</span><span class="p">,</span>
                     <span class="s1">&#39;ytick.right&#39;</span> <span class="p">:</span> <span class="kc">True</span><span class="p">,</span>
                     <span class="s1">&#39;ytick.direction&#39;</span> <span class="p">:</span> <span class="s1">&#39;in&#39;</span>
                    <span class="p">})</span>
</pre></div>
</div>
</div>
<div class="section" id="Building-Blocks-of-Neural-Networks">
<h2>Building Blocks of Neural Networks<a class="headerlink" href="#Building-Blocks-of-Neural-Networks" title="Permalink to this headline">¶</a></h2>
<p>The basic unit of a neural network. A neuron takes inputs, does some math with them, and produces one output. The neuron below does that with two inputs.</p>
<p><img alt="image" src="../../_images/neuron.png" /></p>
<p>The neuron does now three things.</p>
<ol class="arabic simple">
<li><p>Take input values and multipy by weights</p></li>
</ol>
<p><span class="math">\begin{eqnarray}
x_{1}\rightarrow x_{1} w_{1}\\
x_{2}\rightarrow x_{2} w_{2}
\end{eqnarray}</span></p>
<ol class="arabic simple" start="2">
<li><p>All the weighted inputs are the added to a bias value <span class="math notranslate nohighlight">\(b\)</span></p></li>
</ol>
<dl class="simple">
<dt>:nbsphinx-math:<a href="#id1"><span class="problematic" id="id2">`</span></a>begin{equation}</dt><dd><p>x_{1} w_{1}+ x_{2} w_{2}+b</p>
</dd>
</dl>
<p>end{equation}`</p>
<ol class="arabic simple" start="3">
<li><p>The output is generated by applying a function <span class="math notranslate nohighlight">\(f()\)</span> <span class="math">\begin{equation}
y=f( x_{1} w_{1}+ x_{2} w_{2}+b)
\end{equation}</span></p></li>
</ol>
<p>This function is called activation function. The activation function is used to turn an unbounded input value into a bounded output value with a predictable range. A commonly used activation function is the <code class="docutils literal notranslate"><span class="pre">sigmoid</span> <span class="pre">function</span></code>.</p>
<p><span class="math">\begin{equation}
f(x)=\frac{1}{1+e^{-x}}
\end{equation}</span></p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;input&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;output&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<a class="reference internal image-reference" href="../../_images/notebooks_L13_1_neural_networks_8_0.png"><img alt="../../_images/notebooks_L13_1_neural_networks_8_0.png" src="../../_images/notebooks_L13_1_neural_networks_8_0.png" style="width: 348px; height: 219px;" /></a>
</div>
</div>
<p>If we now have this kind of two input neuron with the weights <span class="math notranslate nohighlight">\(w\)</span> and the bias value <span class="math notranslate nohighlight">\(b\)</span></p>
<p><span class="math">\begin{eqnarray}
w=[0,1]\\
b=4
\end{eqnarray}</span></p>
<p>we may supply and input</p>
<p><span class="math">\begin{eqnarray}
x=[2,3]
\end{eqnarray}</span></p>
<p>which gives writing it a s a dot product</p>
<p><span class="math">\begin{equation}
y=f(w\cdot x+b)=f(7)=0.999
\end{equation}</span></p>
<p>This procedure of propagating the input values to obtain and output value is called <strong>feedforward</strong>.</p>
</div>
<div class="section" id="Making-a-Neuron">
<h2>Making a Neuron<a class="headerlink" href="#Making-a-Neuron" title="Permalink to this headline">¶</a></h2>
<p>We would like to squeeze our knowledge not into a class, which we can use to create neuron objects that are arranged in a network.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">Neuron</span><span class="p">:</span>
  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">weights</span> <span class="o">=</span> <span class="n">weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">bias</span> <span class="o">=</span> <span class="n">bias</span>

  <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">):</span>
    <span class="c1"># Weight inputs, add bias, then use the activation function</span>
    <span class="n">total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">inputs</span><span class="p">)</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">bias</span>
    <span class="k">return</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">total</span><span class="p">)</span>


</pre></div>
</div>
</div>
<div class="section" id="Initialize-the-Neuron">
<h3>Initialize the Neuron<a class="headerlink" href="#Initialize-the-Neuron" title="Permalink to this headline">¶</a></h3>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">bias</span> <span class="o">=</span> <span class="mi">4</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="Feedforward">
<h3>Feedforward<a class="headerlink" href="#Feedforward" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>       <span class="c1"># x1 = 2, x2 = 3</span>
<span class="nb">print</span><span class="p">(</span><span class="n">n</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>    <span class="c1"># 0.9990889488055994</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.9990889488055994
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Neural-Network">
<h2>Neural Network<a class="headerlink" href="#Neural-Network" title="Permalink to this headline">¶</a></h2>
<p>It’s now time to combine multiple neurons into a neural network. We want to arrange the neurons in layers. The first layer should be an input layer. The second is a so-called hidden layer and finally we have an output layer. Each layer can contain several neurons. We chose a rather simple structure, which looks like that</p>
<p><img alt="network" src="../../_images/network.png" /></p>
</div>
<div class="section" id="The-network-class">
<h2>The network class<a class="headerlink" href="#The-network-class" title="Permalink to this headline">¶</a></h2>
<p>The class below defines the network as we have depicted it in the image above. The input neurons just contain the input values, so the hidden neurosn <span class="math notranslate nohighlight">\(h_{1}\)</span>, <span class="math notranslate nohighlight">\(h_{2}\)</span> are the first neuron we need.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">:</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
    <span class="n">bias</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># The Neuron class here is from the previous section</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h1</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">h2</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">o1</span> <span class="o">=</span> <span class="n">Neuron</span><span class="p">(</span><span class="n">weights</span><span class="p">,</span> <span class="n">bias</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">out_h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h1</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="n">out_h2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">h2</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># The inputs for o1 are the outputs from h1 and h2</span>
    <span class="n">out_o1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">o1</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">out_h1</span><span class="p">,</span> <span class="n">out_h2</span><span class="p">]))</span>

    <span class="k">return</span> <span class="n">out_o1</span>


</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.7216325609518421
</pre></div></div>
</div>
<div class="section" id="Create-the-network">
<h3>Create the network<a class="headerlink" href="#Create-the-network" title="Permalink to this headline">¶</a></h3>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">network</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">network</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.7216325609518421
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Data-and-loss">
<h2>Data and loss<a class="headerlink" href="#Data-and-loss" title="Permalink to this headline">¶</a></h2>
<div class="section" id="We-need-data">
<h3>We need data<a class="headerlink" href="#We-need-data" title="Permalink to this headline">¶</a></h3>
<p>The network should infer trends from certain data. For that purpose, we need to supply the network with the appropriate data. We will use here data for persond with specific weight and height. The network should learn to predict the gender based on those data.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 23%" />
<col style="width: 27%" />
<col style="width: 23%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Weight</p></th>
<th class="head"><p>Height</p></th>
<th class="head"><p>Gender</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mia</p></td>
<td><p>133</p></td>
<td><p>65</p></td>
<td><p>F</p></td>
</tr>
<tr class="row-odd"><td><p>Bob</p></td>
<td><p>160</p></td>
<td><p>72</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-even"><td><p>Charlie</p></td>
<td><p>152</p></td>
<td><p>70</p></td>
<td><p>M</p></td>
</tr>
<tr class="row-odd"><td><p>Diana</p></td>
<td><p>120</p></td>
<td><p>60</p></td>
<td><p>F</p></td>
</tr>
</tbody>
</table>
<p>To make the data more useful for the network we subtract mean values from the data and represent the gender in terms of a number.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 18%" />
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 15%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Weight (-135)</p></th>
<th class="head"><p>Height (-66)</p></th>
<th class="head"><p>Gender</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mia</p></td>
<td><p>-2</p></td>
<td><p>-1</p></td>
<td><p>1</p></td>
</tr>
<tr class="row-odd"><td><p>Bob</p></td>
<td><p>25</p></td>
<td><p>6</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-even"><td><p>Charlie</p></td>
<td><p>17</p></td>
<td><p>4</p></td>
<td><p>0</p></td>
</tr>
<tr class="row-odd"><td><p>Diana</p></td>
<td><p>-15</p></td>
<td><p>-6</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="Loss">
<h3>Loss<a class="headerlink" href="#Loss" title="Permalink to this headline">¶</a></h3>
<p>Since we have now data, we also need to define a measure for how far the output deviates from the input. This measure is called <strong>loss</strong>. The mean squared error, as it appeared already during our fitting lecture, is defined as</p>
<p><span class="math">\begin{equation}
MSE=\frac{1}{n}\sum_{i=1}^{n}(y_{\rm true}-y_{\rm pred})^2
\end{equation}</span></p>
<p>for a number of <span class="math notranslate nohighlight">\(n\)</span> datasets. Here <span class="math notranslate nohighlight">\(y_{\rm pred}\)</span> is the data that is predicted by the network and <span class="math notranslate nohighlight">\(y_{\rm true}\)</span> is the value which represents the truth for a specific person for example, e.g. (Alice: <span class="math notranslate nohighlight">\(y_{\rm true}=1\)</span>, female).</p>
<p>The results of the error calculation is thus lower, if the ourput of the network is closer to the true value of the training data.</p>
<p>The loss function is easily implemented.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[25]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">mse_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">((</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">We</span> <span class="n">supply</span> <span class="n">some</span> <span class="n">data</span> <span class="n">to</span> <span class="n">calculate</span> <span class="n">th</span> <span class="n">emean</span> <span class="n">squared</span> <span class="n">error</span><span class="o">.</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[26]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">y_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">y_pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[27]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="nb">print</span><span class="p">(</span><span class="n">mse_loss</span><span class="p">(</span><span class="n">y_true</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.5
</pre></div></div>
</div>
</div>
</div>
<div class="section" id="Training-the-network">
<h2>Training the network<a class="headerlink" href="#Training-the-network" title="Permalink to this headline">¶</a></h2>
<div class="section" id="Backpropagation">
<h3>Backpropagation<a class="headerlink" href="#Backpropagation" title="Permalink to this headline">¶</a></h3>
<p>The goal of all neural network training procedures is to minimize the loss and we have to find a way to minimize that loss. This is not so much different from our fitting of function values before. If we just take one dataset</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 11%" />
<col style="width: 36%" />
<col style="width: 36%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Name</p></th>
<th class="head"><p>Weight (-135)</p></th>
<th class="head"><p>Height (-66)</p></th>
<th class="head"><p>Gender</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Mia</p></td>
<td><p>-2</p></td>
<td><p>-1</p></td>
<td><p>1</p></td>
</tr>
</tbody>
</table>
<p>and calculate the <span class="math notranslate nohighlight">\(MSE\)</span></p>
<div class="math notranslate nohighlight">
\[MSE=L=\frac{1}{1}\sum_{i=1}^{1}(y_{\rm true}-y_{\rm pred})^2=(y_{\rm true}-y_{\rm pred})^2=(1-y_{\rm pred})^2\]</div>
<p>We know that the calculation of the output value of the network <span class="math notranslate nohighlight">\(y_{\rm pred}\)</span> depends on the individual weights combining the inputs of each neuron. The output loss is thefore a function of all weights <span class="math notranslate nohighlight">\(w\)</span> and bias values as well <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p><img alt="weights" src="../../_images/weights.png" /></p>
<p>In our simple system, we have 6 weights and 3 bias values.</p>
<div class="math notranslate nohighlight">
\[L(w_{1},w_{2},w_{3},w_{4},w_{4},w_{5},b_{1},b_{2},b_{3})\]</div>
<p>which makes the loss function depend on the variation of those 9 parameters. The strength by which the value of the loss changes, when we vary <span class="math notranslate nohighlight">\(w_{1}\)</span> is given by its partial derivative</p>
<div class="math notranslate nohighlight">
\[\frac{\partial L}{\partial w_{1}}=\frac{\partial L}{\partial y_{\rm pred}}\frac{\partial y_{\rm pred}}{\partial w_{1}}\]</div>
<p>As we know the true value and we have calculated the loss for a single dataset we can calculate the first part on the right side of the partial derivative.</p>
<div class="math notranslate nohighlight">
\[\frac{\partial L}{\partial y_{\rm pred}}=\frac{\partial (1-y_{\rm pred})^2}{\partial y_{\rm pred}}=-2(1-y_{\rm pred})\]</div>
<p>The second part needs to calculate the deritative of <span class="math notranslate nohighlight">\(y_{\rm pred}\)</span> with respect to <span class="math notranslate nohighlight">\(w_{1}\)</span>. Since</p>
<div class="math notranslate nohighlight">
\[y_{\rm pred}=o_{1}=f(w_{5}h_{1}+w_{6}h_{2}+b_{3})\]</div>
<p>and only <span class="math notranslate nohighlight">\(h_{1}\)</span> is effected by <span class="math notranslate nohighlight">\(w_{1}\)</span>, we can write</p>
<div class="math notranslate nohighlight">
\[\frac{\partial y_{\rm pred}}{\partial w_{1}}=\frac{\partial y_{\rm pred}}{\partial h_{1}}\frac{\partial h_{1}}{\partial w_{1}}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\frac{\partial y_{\rm pred}}{\partial h_{1}}=w_{5} f^{\prime}(w_{5}h_{1}+w_{6}h_{2}+b_{3})\]</div>
<p>We can apply the same kind of chain rule for <span class="math notranslate nohighlight">\(h_{1}\)</span>.</p>
<div class="math notranslate nohighlight">
\[h_{1}=f(w_{1}x_{1}+w_{2}x_{2}+b1)\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\frac{\partial h_{1}}{\partial w_{1}}=x_{1}f^{\prime}(w_{1}x_{1}+w_{2}x_{2}+b1)\]</div>
<p>The derivative <span class="math notranslate nohighlight">\(f^{\prime}\)</span> is just given by the derivative of the sigmoid function</p>
<div class="math notranslate nohighlight">
\[f^{\prime}(x)=\frac{e^{-x}}{(1+e^{-x})^2}=f(x)(1-f(x))\]</div>
<p>Thus, stitching all together we obtain</p>
<div class="math notranslate nohighlight">
\[\frac{\partial L}{\partial w_{1}}=\frac{\partial L}{\partial y_{}\rm pred}\frac{\partial y_{\rm pred}}{\partial h_{1}}\frac{\partial h_{1}}{\partial h_{1}}\]</div>
<p>which is known as the backpropagation step of the calculation.</p>
</div>
<div class="section" id="Stochastic-Gradient-Descent">
<h3>Stochastic Gradient Descent<a class="headerlink" href="#Stochastic-Gradient-Descent" title="Permalink to this headline">¶</a></h3>
<p>We have all the tools we need to train a neural network now! We’ll use an optimization algorithm called stochastic gradient descent (SGD) that tells us how to change our weights and biases to minimize loss. It’s basically just this update equation</p>
<div class="math notranslate nohighlight">
\[w_{1}\leftarrow w_{1}-\eta\frac{\partial L}{\partial w_{1}}\]</div>
<p>where <span class="math notranslate nohighlight">\(\eta\)</span> is a constant called the learning rate that controls how fast we train. All we’re doing is subtracting <span class="math notranslate nohighlight">\(\eta \partial L/\partial w_{1}\)</span> from <span class="math notranslate nohighlight">\(w_{1}\)</span></p>
<ul class="simple">
<li><p>If <span class="math notranslate nohighlight">\(\partial L/\partial w_{1}\)</span> is positive, <span class="math notranslate nohighlight">\(w_{1}\)</span> will decrease, which makes L decrease.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\partial L/\partial w_{1}\)</span> is negative, <span class="math notranslate nohighlight">\(w_{1}\)</span> will increase, which makes L decrease. If we do this for every weight and bias in the network, the loss will slowly decrease and our network will improve. Our training process will look like this: Choose one sample from our dataset. This is what makes it stochastic gradient descent — we only operate on one sample at a time. Calculate all the partial derivatives of loss with respect to weights or biases (e.g. ∂L/∂w1​, ∂L​/∂w2​,
etc). Use the update equation to update each weight and bias. Go back to step 1. Let’s see it in action!</p></li>
</ul>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[31]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">def</span> <span class="nf">deriv_sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
  <span class="c1"># Derivative of sigmoid: f&#39;(x) = f(x) * (1 - f(x))</span>
  <span class="n">fx</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">fx</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">fx</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[32]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="k">class</span> <span class="nc">Network</span><span class="p">:</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="c1"># Weights</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w4</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w5</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">w6</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>

    <span class="c1"># Biases</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">b3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">()</span>

  <span class="k">def</span> <span class="nf">feedforward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="c1"># x is a numpy array with 2 elements.</span>
    <span class="n">h1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span><span class="p">)</span>
    <span class="n">h2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w4</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span><span class="p">)</span>
    <span class="n">o1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">w5</span> <span class="o">*</span> <span class="n">h1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w6</span> <span class="o">*</span> <span class="n">h2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b3</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">o1</span>

  <span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">all_y_trues</span><span class="p">):</span>
    <span class="sd">&#39;&#39;&#39;</span>
<span class="sd">    - data is a (n x 2) numpy array, n = # of samples in the dataset.</span>
<span class="sd">    - all_y_trues is a numpy array with n elements.</span>
<span class="sd">      Elements in all_y_trues correspond to those in data.</span>
<span class="sd">    &#39;&#39;&#39;</span>
    <span class="n">learn_rate</span> <span class="o">=</span> <span class="mf">0.1</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">1000</span> <span class="c1"># number of times to loop through the entire dataset</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
      <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y_true</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">all_y_trues</span><span class="p">):</span>
        <span class="c1"># --- Do a feedforward (we&#39;ll need these values later)</span>
        <span class="n">sum_h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b1</span>
        <span class="n">h1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">sum_h1</span><span class="p">)</span>

        <span class="n">sum_h2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w4</span> <span class="o">*</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b2</span>
        <span class="n">h2</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">sum_h2</span><span class="p">)</span>

        <span class="n">sum_o1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w5</span> <span class="o">*</span> <span class="n">h1</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">w6</span> <span class="o">*</span> <span class="n">h2</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">b3</span>
        <span class="n">o1</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">sum_o1</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">o1</span>

        <span class="c1"># --- Calculate partial derivatives.</span>
        <span class="c1"># --- Naming: d_L_d_w1 represents &quot;partial L / partial w1&quot;</span>
        <span class="n">d_L_d_ypred</span> <span class="o">=</span> <span class="o">-</span><span class="mi">2</span> <span class="o">*</span> <span class="p">(</span><span class="n">y_true</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="c1"># Neuron o1</span>
        <span class="n">d_ypred_d_w5</span> <span class="o">=</span> <span class="n">h1</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_o1</span><span class="p">)</span>
        <span class="n">d_ypred_d_w6</span> <span class="o">=</span> <span class="n">h2</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_o1</span><span class="p">)</span>
        <span class="n">d_ypred_d_b3</span> <span class="o">=</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_o1</span><span class="p">)</span>

        <span class="n">d_ypred_d_h1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w5</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_o1</span><span class="p">)</span>
        <span class="n">d_ypred_d_h2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w6</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_o1</span><span class="p">)</span>

        <span class="c1"># Neuron h1</span>
        <span class="n">d_h1_d_w1</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_h1</span><span class="p">)</span>
        <span class="n">d_h1_d_w2</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_h1</span><span class="p">)</span>
        <span class="n">d_h1_d_b1</span> <span class="o">=</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_h1</span><span class="p">)</span>

        <span class="c1"># Neuron h2</span>
        <span class="n">d_h2_d_w3</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_h2</span><span class="p">)</span>
        <span class="n">d_h2_d_w4</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_h2</span><span class="p">)</span>
        <span class="n">d_h2_d_b2</span> <span class="o">=</span> <span class="n">deriv_sigmoid</span><span class="p">(</span><span class="n">sum_h2</span><span class="p">)</span>

        <span class="c1"># --- Update weights and biases</span>
        <span class="c1"># Neuron h1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w1</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_h1</span> <span class="o">*</span> <span class="n">d_h1_d_w1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w2</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_h1</span> <span class="o">*</span> <span class="n">d_h1_d_w2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b1</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_h1</span> <span class="o">*</span> <span class="n">d_h1_d_b1</span>

        <span class="c1"># Neuron h2</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w3</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_h2</span> <span class="o">*</span> <span class="n">d_h2_d_w3</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w4</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_h2</span> <span class="o">*</span> <span class="n">d_h2_d_w4</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b2</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_h2</span> <span class="o">*</span> <span class="n">d_h2_d_b2</span>

        <span class="c1"># Neuron o1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w5</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_w5</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">w6</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_w6</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">b3</span> <span class="o">-=</span> <span class="n">learn_rate</span> <span class="o">*</span> <span class="n">d_L_d_ypred</span> <span class="o">*</span> <span class="n">d_ypred_d_b3</span>

      <span class="c1"># --- Calculate total loss at the end of each epoch</span>
      <span class="k">if</span> <span class="n">epoch</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">y_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feedforward</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">mse_loss</span><span class="p">(</span><span class="n">all_y_trues</span><span class="p">,</span> <span class="n">y_preds</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch </span><span class="si">%d</span><span class="s2"> loss: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">loss</span><span class="p">))</span>

</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[37]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Define dataset</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
  <span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span>  <span class="c1"># Alice</span>
  <span class="p">[</span><span class="mi">25</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>   <span class="c1"># Bob</span>
  <span class="p">[</span><span class="mi">17</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>   <span class="c1"># Charlie</span>
  <span class="p">[</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">],</span> <span class="c1"># Diana</span>
<span class="p">])</span>

<span class="n">all_y_trues</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
  <span class="mi">1</span><span class="p">,</span> <span class="c1"># Alice</span>
  <span class="mi">0</span><span class="p">,</span> <span class="c1"># Bob</span>
  <span class="mi">0</span><span class="p">,</span> <span class="c1"># Charlie</span>
  <span class="mi">1</span><span class="p">,</span> <span class="c1"># Diana</span>
<span class="p">])</span>

<span class="c1"># Train our neural network!</span>
<span class="n">network</span> <span class="o">=</span> <span class="n">Network</span><span class="p">()</span>
<span class="n">network</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">all_y_trues</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Epoch 0 loss: 0.233
Epoch 10 loss: 0.185
Epoch 20 loss: 0.157
Epoch 30 loss: 0.134
Epoch 40 loss: 0.113
Epoch 50 loss: 0.095
Epoch 60 loss: 0.080
Epoch 70 loss: 0.067
Epoch 80 loss: 0.057
Epoch 90 loss: 0.049
Epoch 100 loss: 0.043
Epoch 110 loss: 0.037
Epoch 120 loss: 0.033
Epoch 130 loss: 0.030
Epoch 140 loss: 0.027
Epoch 150 loss: 0.024
Epoch 160 loss: 0.022
Epoch 170 loss: 0.021
Epoch 180 loss: 0.019
Epoch 190 loss: 0.018
Epoch 200 loss: 0.017
Epoch 210 loss: 0.016
Epoch 220 loss: 0.015
Epoch 230 loss: 0.014
Epoch 240 loss: 0.013
Epoch 250 loss: 0.012
Epoch 260 loss: 0.012
Epoch 270 loss: 0.011
Epoch 280 loss: 0.011
Epoch 290 loss: 0.010
Epoch 300 loss: 0.010
Epoch 310 loss: 0.009
Epoch 320 loss: 0.009
Epoch 330 loss: 0.009
Epoch 340 loss: 0.008
Epoch 350 loss: 0.008
Epoch 360 loss: 0.008
Epoch 370 loss: 0.008
Epoch 380 loss: 0.007
Epoch 390 loss: 0.007
Epoch 400 loss: 0.007
Epoch 410 loss: 0.007
Epoch 420 loss: 0.006
Epoch 430 loss: 0.006
Epoch 440 loss: 0.006
Epoch 450 loss: 0.006
Epoch 460 loss: 0.006
Epoch 470 loss: 0.006
Epoch 480 loss: 0.005
Epoch 490 loss: 0.005
Epoch 500 loss: 0.005
Epoch 510 loss: 0.005
Epoch 520 loss: 0.005
Epoch 530 loss: 0.005
Epoch 540 loss: 0.005
Epoch 550 loss: 0.005
Epoch 560 loss: 0.005
Epoch 570 loss: 0.004
Epoch 580 loss: 0.004
Epoch 590 loss: 0.004
Epoch 600 loss: 0.004
Epoch 610 loss: 0.004
Epoch 620 loss: 0.004
Epoch 630 loss: 0.004
Epoch 640 loss: 0.004
Epoch 650 loss: 0.004
Epoch 660 loss: 0.004
Epoch 670 loss: 0.004
Epoch 680 loss: 0.004
Epoch 690 loss: 0.004
Epoch 700 loss: 0.004
Epoch 710 loss: 0.003
Epoch 720 loss: 0.003
Epoch 730 loss: 0.003
Epoch 740 loss: 0.003
Epoch 750 loss: 0.003
Epoch 760 loss: 0.003
Epoch 770 loss: 0.003
Epoch 780 loss: 0.003
Epoch 790 loss: 0.003
Epoch 800 loss: 0.003
Epoch 810 loss: 0.003
Epoch 820 loss: 0.003
Epoch 830 loss: 0.003
Epoch 840 loss: 0.003
Epoch 850 loss: 0.003
Epoch 860 loss: 0.003
Epoch 870 loss: 0.003
Epoch 880 loss: 0.003
Epoch 890 loss: 0.003
Epoch 900 loss: 0.003
Epoch 910 loss: 0.003
Epoch 920 loss: 0.003
Epoch 930 loss: 0.003
Epoch 940 loss: 0.003
Epoch 950 loss: 0.002
Epoch 960 loss: 0.002
Epoch 970 loss: 0.002
Epoch 980 loss: 0.002
Epoch 990 loss: 0.002
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[38]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># Make some predictions</span>
<span class="n">emily</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="o">-</span><span class="mi">7</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># 128 pounds, 63 inches</span>
<span class="n">frank</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">20</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>  <span class="c1"># 155 pounds, 68 inches</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Emily: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">network</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">emily</span><span class="p">))</span> <span class="c1"># 0.951 - F</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Frank: </span><span class="si">%.3f</span><span class="s2">&quot;</span> <span class="o">%</span> <span class="n">network</span><span class="o">.</span><span class="n">feedforward</span><span class="p">(</span><span class="n">frank</span><span class="p">))</span> <span class="c1"># 0.039 - M</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Emily: 0.950
Frank: 0.040
</pre></div></div>
</div>
<script type="application/vnd.jupyter.widget-state+json">
{"state": {}, "version_major": 2, "version_minor": 0}
</script></div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, Frank Cichos
      <span class="lastupdated">
        Last updated on Jun 28, 2020.
      </span>

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>